\documentclass[10pt,onecolumn,draftclsnofoot]{IEEEtran} %may need comma after
\usepackage{times}
\usepackage{graphicx}
\usepackage{array}
\usepackage{float}
\usepackage{geometry}
\usepackage{titling}
\usepackage{hyperref}
\usepackage{setspace}
\usepackage{listings}
\usepackage{color}
\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}
\lstset{
        basicstyle=\footnotesize,
        commentstyle=\color{mygreen},
        frame=single,
        keywordstyle=\color{blue},
        numberstyle=\tiny\color{mygray},
        numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
        numbersep=5pt,
        language=bash,
        rulecolor=\color{black},
        }
\setlength{\parindent}{1cm}
\newgeometry{left=1.905cm, right=1.905cm}
%this is a comment
\title{ Project Two, CS444, Spring 2018, Homework Group 10}
\author{Kamron Ebrahimi, Maximillian Schmidt \& Brendan Byers \\ ebrahimk, schmidtm, byersbr }
\date{\today}

\begin{document}

\begin{titlingpage}
\maketitle
\begin{abstract}
\begin{singlespace}
This report details the process of writing an I/O scheduler module and incorperating the module into the Linux kernel. The I/O scheduler implemented in this project was the CLOOk scheduler. To implement this module the NOOP scheduler, written by Jens Axboe was copied and manipulated to produce a scheduler which performs request merging and services requests in a sawtooth fashion. To complete this project the \textbf{block/Makefile} and \textbf{block/Kconfig.iosched} files were manipulated in order to build the new scheduling algorithm and the QEMU invocation command was tweaked to disable virtio and allow for networking access.
\end{singlespace}
\end{abstract}
\end{titlingpage}


\tableofcontents

\newpage
\begin{singlespace}
\section{\bf  Design and Implementation}

  \normalfont \indent Prior to designing any solution to this algorithm we first spent several days analyzing the Linux kernel source code. Files of particular interest included the \textit{block/noop-iosched.c}, \textit{include/linux/list.h} and \textit{block/elevator.c}. After studying these files as well as all of the other header files included in the NOOP scheduler, the team had a rough idea of how block drivers functioned. At this point in the design process however the team decided it would be beneficial to experiment with \textit{printk} statements, and try to implement a new I/O scheduler. After some substantial research the team learned that the \textit{block/Makefile} and \textit{block/Kconfig.iosched} files had to be edited to include the new scheduler.

  \normalfont \indent With these files edited to build the new LOOk scheduler into the kernel upon compilation, all that was left to get the new scheduler incorporated into the VM was to change the QEMU invocation command. In order to port the new scheduler into the VM, virtio was disabled. The \textit{-net none} command was also omitted so files from the git repository could be grabbed with \textit{wget}. Finally the kernel image \textit{bzImage-qemux86.bin} was changed to point to \textit{/arch/x86/boot/bzImage}. This allows the VM to "see" the newly built scheduler. In this fashion we start the VM and switch to the LOOK scheduler using the following commands.

  \begin{itemize}
        \item \textbf{qemu-system-i386 -gdb tcp::5510 -S -nographic -kernel ./arch/x86/boot/bzImage -drive file=core-image-lsb-sdk-qemux86.ext4 -enable-kvm -usb -localtime --no-reboot --append "root=/dev/hda rw console=ttyS0 debug"}
        \item \textbf{echo look > /sys/block/hda/queue/scheduler}
  \end{itemize}

        \normalfont \indent With the aforementioned edits made the team created the \textit{look-iosched.c} file as a copy of \textit{noop-iosched.c}. Now edits could be made to the new scheduling algorithm, the kernel could be recompiled and the scheduler could be switched to and tested within the VM. With newly setup testing environment, the team researched the finer details of the LOOK algorithm. The LOOK I/O scheduler sorts new requests in a fashion relative to the current position of the read/write disk head. The algorithm needs to service all requests in one direction of the hard drive disk, upon reaching the largest request in the dispatch queue the read write head of the disk returns to the far starting terminal and restarts the process. Keeping this in mind the team knew that the location at which new requests were added needed to be relative to the current location of the read write head. It was decided that a global \textit{sector\_t} variable be maintained which contained the sector value of the last dispatched requests or the physical position of the read write head on the hard drive. Incoming requests could then be sorted in the \textit{look\_add\_request()} function prior to being dispatched.

        \normalfont \indent From a high level perspective the implementation of the LOOK algorithm first looks at the sector number of a new request. If the sector value of the new request is greater than the current sector at which the read/write head is located then the new request can be serviced on the current run of the read write head. The request is thus inserted at a location that is less than the value of the read/write head's location or less than the value of some larger request to be serviced on the current run of the read/write head. If on the other hand the incoming request lies at a sector which is less than the sector at which the read/write head is located then new request will have to be serviced on the next run of the read/write head. Thus the read/write head would need to service the largest request on its current run, reposition itself back at the start of the disk and perform another run in order to service the new request. Below is the implementation of CLOOK used for this assignment, the variable \textit{disk\_head} is at the global scope and is reassigned to the most recently dispatch request's sector\_t value.

\newpage
\lstinputlisting[language=c]{algorithm.c}
\begin{center}
Figure 1.1 CLOOK Algorithm Implementation
\end{center}

\newpage
\section{\bf Questions}

        \textbf{What do you think the main point of this assignment is?}\\

                \normalfont \indent The purpose of this assignment was to gain first hand experience developing within the Linux Kernel. Specifically this assignment was meant to familiarize individuals with some of the available data structures and api's within the kernel as well as how one must go about configuring and building a custom module within the kernel. The assignment also forced us to become more familiar with the QEMU environment and invocation commands as well as some underlying principles in writing block device drivers.\\

        \textbf{How did you personally approach the problem?}\\

                \normalfont \indent This being the teams first up close encounter with kernel source code we were all initially overwhelmed by the density of the source code and seemingly endless references to functions and macros in other header files. To exacerbate the situation the team quickly found out how poorly documented the Linux source code really was. Without extensive documentation the first step was to trace through the source code and get a rough idea of how all of the small components worked together. This was surprisingly difficult and time consuming and each tema member encountered multiple lines of code with syntax they had never before encountered.

                \normalfont \indent The team recognized that the logical place to start was the NOOP scheduler. The most difficult part of this program to grasp was the multi queued architecture of the program. We knew that the NOOP scheduler performed no sorting and simply maintained a FIFO queue, thus it was initially very confusing trying to understand the flow of requests between \textit{noop\_add\_request()} and \textit{noop\_dispatch()}. We eventually determined through the use of \textit{printk()} statements that requests could be sorted in either of these functions and that requests are initially added to the dispatch queue via \textit{noop\_add\_request()}. With this determined we figured the most efficient way to implementing the algorithm was to perform the insertion sort within this function and maintain the order as requests were placed in the dispatch queue. To track the disk heads position a global variable was used which was reassigned after every execution of \textit{noop\_dispatch()} to equal the sector\_t value of the most recently dispatch request. With this global variable incoming requests could be placed within the request queue relative to the disk heads position.\\


        %discuss testing and python scripts used to grab and parse data 
        \textbf{How did you ensure your solution was correct?}\\

                \normalfont \indent The team ran into several roadblocks when trying to test the solution. This was primarily caused by the nature of incoming requests. Initially a python script was written to generate I/O in one folder. However the requests made by the scheduler when executing this script were all in the same location and in ascending order, thus the sorting functionality of the algorithm was not tested. The script was edited to create multiple different folders and perform read write operation on files within those folders. This method also was ineffective. Python produced I/O requests at a rate slower than shedulers ability to process them. Thus a request queue was never able to form and requests were processed as soon as they arrived. The solution the team arrived at was to write a c++ file to produce I/O. C++ executes much faster than Python and as a result of this method request arrived at an extremely fast rate throttling the scheduling algorithm and causing the requests to queue up. Once a queue started to form it became easy to see how the algorithm sorted incoming requests. Additionally, in order to avoid the issue of reporting requests that were serviced upon arrival, the algorithm makes use of a global variable \textit{queue\_exists}. If \textit{look\_add\_request()} is called and the queue is empty this variable is set to false, thus causing a \textit{printk()} statement within \textit{look\_dispatch()} to not trigger. In this fashion only requests thats are sorted by the LOOK algorithm are displayed allowing the team to verify that the algorithm works properly. The team used \textit{printk} statements extensively in their implementation to provide status reports on the inner workings of the algorithm and wrote a test script for the TA's which changes the scheduler, executes the C++ code, then grabs all of the relevant kernel statements which detail the order of the dispatch queue and prints the statements to the console. Below is a graph of data collected when using our algorithm showing the sector of the request serviced versus the time at which the request was serviced. A sharp sawtooth pattern can be seen, an expected pattern for the CLOOK algorithm.\\

	\begin{center}	
        \begin{figure}[H]
                \includegraphics[width =\linewidth,scale=0.5]{data_plot.eps}
                \caption{Sectors of Dispatched Requests VS Time}
                \label{fig: Class Diagram 1}
        \end{figure}
	\end{center}

\newpage
        \textbf{What did you learn?}\\
        \normalfont \indent This assignment threw the entire team into deep waters with no paddle. No team meber had looked much into the Linux source code, let alone ever written a block device driver. To complete this assignment a great deal of overhead research was done. The team learned how to edit the Kconfig files located throughout the kernel as well as how to use the various data structures and API's provided by the Kernel developers. Lastly and most importantly the team grew comfortable in different debugging methods for Kernel programming. The \textit{printk()} function was extremely helpful in learning how some poorly documented, confusing functions worked.\\

        \textbf{How should the TA evaluate your work?}\\
        
	\normalfont \indent The below steps if followed correctly will get you into a running instance of VM, download a test script and a C++ file which will produce fast I/O. The test script will change the in use scheduler, compile the C++ file and execute the file. The LOOK scheduler implemented in our patch file uses \textit{printk()} statements which print "LOOK\_DISPATCH" then the sector of the request dispatched. These statements can be accessed using \textit{dmesg}. We pipe this into grep and look for the "LOOK\_DIPATCH" string and grab those values. The values are written to a file and the contents are printed to the console. Scroll through the results which show the order of requests being dispatched. You will see that requests are sorted in a wave like pattern as the head of the read/write disk services requests from small to large then immediatley jumps back to a small request as specified in the CLOOK algorithm.\\


	\begin{enumerate}
                \item Apply the patch file for the CLOOK algorithm implementation, this includes an updated \textit{Block/Makefile}, \textit{Block/Kconfig.iosched} and \textit{Block/look-iosched.c} files. 
                \item With the files incorperated into the kernel run \textbf{qemu-system-i386 -gdb tcp::5510 -S -nographic -kernel ./arch/x86/boot/bzImage -drive file=core-image-lsb-sdk-qemux86.ext4 -enable-kvm -usb -localtime --no-reboot --append "root=/dev/hda rw console=ttyS0 debug"}.
                \item In a seperate terminal within the \textit{linux-yocto-3.19.2} on the os2 server run \textbf{\$GDB vmlinux}.
		\item In the same terminal with GDB running enter \textbf{target remote: 5510} then \textbf{continue}.
		\item The VM should start up, when prompted for login credentials enter \textbf{root}.
		\item At the command line of the VM enter \textbf{wget https://raw.githubusercontent.com/ebrahimk/CS444/master/project2/gen\_IO.cpp}.
		\item At the command line again, run \textbf{wget https://raw.githubusercontent.com/ebrahimk/CS444/master/project2/test.sh}.
		\item Run \textbf{chmod +x test.sh}.
		\item Finally run \textbf{./test.sh}. Please note that this generates a ton of I/O so it will take a little while. 
		\item Run \textbf{cat test/data\_results}
        \end{enumerate}
	

\newpage
\section{\bf Work Log}

                \input{changelog.tex}

\newpage


\end{singlespace}
\restoregeometry
\end{document}

